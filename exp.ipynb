{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:/Users/bento/AppData/Local/ESRI/conda/envs/arcgispro-py3-clone/python.exe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import arcpy\n",
    "import re \n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "# Data from https://feederwatch.org/explore/raw-dataset-requests/\n",
    "\n",
    "def get_species_codes() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function queries the Species Codes sheet from the FeederWatch Data Dictionary. The\n",
    "    data is available through an excel sheet provided in the data website. This data will be \n",
    "    used to access the corresponding names and families of the different species codes.\n",
    "    Returns a pandas dataframe of species (Fields: species_code, species_name, family)\n",
    "    \"\"\"\n",
    "    # First, set up the url for the data dictionary (Google Drive).\n",
    "    # Credit goes to the following StackOverflow answer for re-formatting the url:\n",
    "    # https://stackoverflow.com/questions/56611698/pandas-how-to-read-csv-file-from-google-drive-public\n",
    "    url = 'https://drive.google.com/file/d/1kHmx2XhA2MJtEyTNMpwqTQEnoa9M7Il2/view?usp=sharing'\n",
    "    url = 'https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "    # Read the Excel Sheet with the Species Codes\n",
    "    species = pd.read_excel(url, sheet_name='Species Codes', header=1)\n",
    "    # Filter and rename columns\n",
    "    species = species[['SPECIES_CODE', 'PRI_COM_NAME_INDXD', 'FAMILY']]/\n",
    "        .rename(columns={'SPECIES_CODE':'species_code', \n",
    "                         'PRI_COM_NAME_INDXD':'species_name',\n",
    "                         'FAMILY':'family'})\n",
    "    return species\n",
    "\n",
    "def clean_fw_data(data:pd.DataFrame, \n",
    "                  birds:pd.DataFrame, \n",
    "                  sub_national_code:list=[]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function cleans the FeederWatch data so that it only contains \n",
    "    relevent fields, accurate (valid) data, specified birds, and specified locations.\n",
    "    Args:\n",
    "    - data: a pandas dataframe; raw data downloaded from FeederWatch site\n",
    "    - birds: species data - output of get_species_codes(). \n",
    "             * Note: It can be a subset of this data (e.g., a specific family)\n",
    "    - sub_national_code: list of `subnational1_code` fields to filter to \n",
    "    Returns a subset of the original data input, with cleaned field names.\n",
    "    \"\"\"\n",
    "    # All available names of fields in dataset\n",
    "    all_names = ['loc_id', 'latitude', 'longitude', 'subnational1_code', \n",
    "                 'entry_technique', 'sub_id', 'obs_id', 'month', 'day',\n",
    "                 'year', 'proj_period_id', 'species_code', 'how_many',\n",
    "                 'valid', 'reviewed', 'plus_code', 'day1_am', 'day1_pm',\n",
    "                 'day2_am', 'day2_pm', 'effort_hrs_atleast', \n",
    "                 'snow_dep_atleast', 'data_entry_method']\n",
    "    # Output names of fields in dataset (to be kept)\n",
    "    out_names = ['species_code', 'species_name', 'how_many', 'latitude', \n",
    "                 'longitude', 'subnational1_code', 'date']\n",
    "    # Preprocessing (fix column names, include/exclude fields)\n",
    "    data.rename(columns=str.lower, inplace=True)\n",
    "    other_names = [n for n in all_names if n not in data.columns]\n",
    "    data = data.assign(**{name:np.nan for name in other_names if len(other_names) > 0})\n",
    "    # Filter Data by valid, no plus_code, species, optional location\n",
    "    data = data.query(f'valid == 1 & plus_code != 1 & species_code == @birds.species_code.to_list()')\n",
    "    if sub_national_code is not None:\n",
    "        data = data.loc[data.subnational1_code.isin(sub_national_code)]\n",
    "    # Join with species (to get species name)\n",
    "    data = pd.merge(data, birds, how='left', on='species_code')\n",
    "    # Date formatting\n",
    "    data['date'] = pd.to_datetime(dict(year=data.year, \n",
    "                                       month=data.month, \n",
    "                                       day=data.day))\n",
    "    # Return, Ensuring correct order, specific output columns, sorted\n",
    "    return data[out_names].sort_values(by=['date', 'species_name'], ascending=[True, True])\n",
    "\n",
    "def getFeedWatcherData(outfile:str,\n",
    "                       tfs:list, \n",
    "                       birds:pd.DataFrame, \n",
    "                       sub_national_code:list=[], \n",
    "                       out_dir:str='data', \n",
    "                       file_suffix:str='',\n",
    "                       save_:bool=True,\n",
    "                       min_year:int=2017,\n",
    "                       max_year:int=2019) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gets FeederWatch data from website. When reading directly from the URLs \n",
    "    and saving the output, this can take a while (depending on internet speed).\n",
    "    Each independent query (by date range) is saved to a gzipped .csv file,\n",
    "    so if the process is interrupted or re-run, it can be read directly from\n",
    "    that file instead of re-downloaded. Data is also cleaned/filtered (using \n",
    "    `clean_fw_data()`), then concatenated and saved to a final .csv file.\n",
    "    Args: \n",
    "    - outfile: Final output file name\n",
    "    - tfs: Time-frames to get data for\n",
    "    - birds: Species data (Optionally) pre-filtered (e.g., by family)\n",
    "    - sub_national_code: (Optionally) filter by subnational1_code (e.g., U.S. State)\n",
    "    - out_dir: Directory in which to save data\n",
    "    - file_suffix: Suffix of file names\n",
    "    - save_: Whether or not to save the output to a gzipped file\n",
    "    - min_year: minimum year to filter data\n",
    "    - max_year: maximum year to filter data\n",
    "    Returns a pandas dataframe of the selected FeederWatch bird data\n",
    "    \"\"\"\n",
    "    final_out_file = os.path.join(out_dir, outfile)\n",
    "    # First check if the file already exists\n",
    "    if os.path.isfile(final_out_file):\n",
    "        out = pd.read_csv(final_out_file)\n",
    "        out['date'] = pd.to_datetime(out.date)\n",
    "    else:\n",
    "        df_lis = list()\n",
    "        for i in np.arange(0, len(tfs)):\n",
    "            # Read Data (either from URL, or from previously saved data if available)\n",
    "            tf = tfs[i]\n",
    "            out_file = os.path.join(out_dir, f'FW_{tf}_{file_suffix}.csv.gz')\n",
    "            if not os.path.isfile(out_file):\n",
    "                url = 'https://clo-pfw-prod.s3.us-west-2.amazonaws.com/data/PFW_' + tf + '_public.csv'\n",
    "                print(f\"Getting {tf} data from {url}\")\n",
    "                # Read/Clean data\n",
    "                data = clean_fw_data(data=pd.read_csv(url), \n",
    "                                    birds=birds, \n",
    "                                    sub_national_code=sub_national_code)\n",
    "                if save_:\n",
    "                    # If not previously cached, save as gzip\n",
    "                    print(f\"Saving {tf} data to {out_file}\")\n",
    "                    data.to_csv(out_file, compression='gzip', index=False)\n",
    "            else:\n",
    "                print(f\"Reading {tf} data from {out_file}\")\n",
    "                data = pd.read_csv(out_file, compression='gzip')\n",
    "                data['date'] = pd.to_datetime(data.date)\n",
    "            # Append to list\n",
    "            df_lis.append(data)\n",
    "        # Combine list into single dataframe\n",
    "        print(\"Concatenating list of dataframes\")\n",
    "        out = pd.concat(df_lis)\n",
    "        # Filter by date\n",
    "        out = out[out['date'].dt.year >= min_year]\n",
    "        out = out[out['date'].dt.year <= max_year]\n",
    "        # Save to file\n",
    "        out.to_csv(final_out_file, index=False)\n",
    "    return out\n",
    "\n",
    "# Timeframes available in FeederWatch:\n",
    "# '1988_1995', '1996_2000', '2001_2005', '2006_2010', \n",
    "# '2011_2015', '2016_2020', '2021'\n",
    "\n",
    "# Select 2017 - 2019 (Covered by 2019 Land Cover Raster)\n",
    "DATA_TIMEFRAMES = ['2016_2020']\n",
    "# All Species\n",
    "SPECIES = get_species_codes()\n",
    "# Woodpecker Family\n",
    "WOODPECKERS = SPECIES.loc[SPECIES['family'] == 'Picidae (Woodpeckers)']\n",
    "\n",
    "fw = getFeedWatcherData(outfile=\"FW_woodpeckers_NC.csv\",\n",
    "                        tfs=DATA_TIMEFRAMES,\n",
    "                        birds=WOODPECKERS,\n",
    "                        sub_national_code=['US-NC'],\n",
    "                        out_dir='data',\n",
    "                        file_suffix='woodpeckers_NC',\n",
    "                        save_=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Species():\n",
    "    def __init__(self, dataframe:pd.DataFrame) -> None:\n",
    "        self.species_code = dataframe.species_code.to_list()\n",
    "        self.species_name = dataframe.species_name.to_list()\n",
    "        self.family = dataframe.family.to_list()\n",
    "\n",
    "class Bird(Species):\n",
    "    def __init__(self, dataframe:pd.DataFrame, bird_name:str) -> None:\n",
    "        super().__init__(dataframe)\n",
    "        # Get index from original dataframe\n",
    "        bird_idx = np.array([bird_name == b for b in self.species_name])\n",
    "        # Create attributes\n",
    "        self.code = str(np.array(self.species_code)[bird_idx][0])\n",
    "        self.name = str(np.array(self.species_name)[bird_idx][0])\n",
    "        self.family = str(np.array(self.family)[bird_idx][0])\n",
    "        # Adjust name for formatted feature class name attribute\n",
    "        name_parts = self.name.split(', ')\n",
    "        self.formatted_name = re.sub(\"[()]\", \"\", name_parts[1] + \"_\" + name_parts[0])\\\n",
    "                .replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "        self.fc_name = f\"FW_{self.formatted_name}_NC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Globals; Setup\n",
    "PROJ_PATH = \"C:/Users/bento/OneDrive/code_and_data/ncsu-mgist/courses/gis_540/final_project/woodpecker-nc\"\n",
    "DB_PATH = \"fw_GDB.gdb\"\n",
    "# Create File Geodatabase\n",
    "if not os.path.exists(os.path.join(PROJ_PATH, DB_PATH)):\n",
    "    arcpy.CreateFileGDB_management(PROJ_PATH, DB_PATH)\n",
    "arcpy.env.workspace = os.path.join(PROJ_PATH, DB_PATH)\n",
    "DATA_PATH = os.path.join(PROJ_PATH, \"data\")\n",
    "FW_FILE = \"FW_woodpeckers_NC.csv\"\n",
    "BASE_FC = \"FW_woodpeckers_NC\"\n",
    "EXISTING_FCS = arcpy.ListFeatureClasses()\n",
    "# Projected Coordinate System\n",
    "COORD_SYSTEM = arcpy.SpatialReference(\"NAD 1983 StatePlane North Carolina FIPS 3200 (US Feet)\")\n",
    "\n",
    "def batchBirdAnalysis(fw_file:str, \n",
    "                      base_fc:str,\n",
    "                      existing_fcs:list,\n",
    "                      out_coordinate_system:arcpy.SpatialReference, \n",
    "                      data_path:str,\n",
    "                      fw_df:pd.DataFrame,\n",
    "                      species_df:pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Batch processing and analysis of FeederWatch bird data. \n",
    "    Steps:\n",
    "    1) Creates Feature Class from .csv file in file Geodatabase\n",
    "    2) Adds projection, saving to new Feature Class\n",
    "    3) Filters Projected Feature Class by species, saving individual\n",
    "       species to their own Feature Classes in the database\n",
    "    Args: \n",
    "    - fw_file: FeederWatch data .csv file\n",
    "    - base_fc: Base Feature Class name\n",
    "    - existing_fcs: List of existing Feature Classes already saved to the \n",
    "      database (if they already exist, they will be skipped during batch\n",
    "      processing)\n",
    "    - out_coordinate_system: Projected coordinate system\n",
    "    - data_path: Path to feederwatch data\n",
    "    - fw_df: FeederWatch dataframe\n",
    "    - species_df: Species dataframe\n",
    "    \"\"\"\n",
    "    # Create base feature class\n",
    "    if base_fc not in existing_fcs:\n",
    "        arcpy.management.XYTableToPoint(in_table=os.path.join(data_path, fw_file),\n",
    "                                        out_feature_class=base_fc,\n",
    "                                        x_field=\"longitude\", \n",
    "                                        y_field=\"latitude\")\n",
    "    # Add projection to base FC\n",
    "    if f\"{base_fc}_projected\" not in existing_fcs:\n",
    "        arcpy.management.Project(base_fc, \n",
    "                                f\"{base_fc}_projected\", \n",
    "                                out_coordinate_system)\n",
    "    # Add to GDB by species\n",
    "    for species_name in fw_df.species_name.unique():\n",
    "        brd = Bird(dataframe=species_df, bird_name=species_name)\n",
    "        if brd.fc_name not in existing_fcs:\n",
    "            print(f'Adding {brd.name} to gdb...')\n",
    "            arcpy.analysis.Select(f\"{base_fc}_projected\", \n",
    "                                brd.fc_name, \n",
    "                                f\"species_name = '{brd.name}'\")\n",
    "        \n",
    "        \n",
    "batchBirdAnalysis(fw_file=FW_FILE, \n",
    "                  base_fc=BASE_FC,\n",
    "                  existing_fcs=EXISTING_FCS, \n",
    "                  out_coordinate_system=COORD_SYSTEM,\n",
    "                  data_path=DATA_PATH,\n",
    "                  fw_df=fw,\n",
    "                  species_df=WOODPECKERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Get Raster Data\n",
    "# Credit to https://svaderia.github.io/articles/downloading-and-unzipping-a-zipfile/\n",
    "\n",
    "# https://www.lib.ncsu.edu/gis/nlcd\n",
    "if not os.path.isdir('data/NC_Land_Cover/'):\n",
    "    # 2019 only \n",
    "    zipurl = 'https://gisdata.lib.ncsu.edu/fedgov/mrlc/nlcd2019/NC_NLCD2019only.zip'\n",
    "    # 2001 - 2019, every 3 years (NOT IN USE)\n",
    "    # \"https://drive.google.com/uc?id=1555Ox4664hH0kFlakGQwi1nzxrMcC61o&confirm=t&uuid=0edbf032-c3ba-45fe-b111-c3752b7cf8ae&at=ALgDtsw-mvJqXBLq4JMNZJ-5g2b7:1676943369421\"\n",
    "    with urlopen(zipurl) as zipresp:\n",
    "        with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "            zfile.extractall('data/NC_Land_Cover')\n",
    "\n",
    "if 'nc_nlcd2019_Resample_1k' not in arcpy.ListRasters():\n",
    "    # Resample cell size of raster(s), save to gdb\n",
    "    arcpy.management.Resample(\"data/NC_Land_Cover/nc_nlcd2019\", \n",
    "                            \"nc_nlcd2019_Resample_1k\", \n",
    "                            \"1000 1000\", \n",
    "                            \"MAJORITY\")\n",
    "\n",
    "# Connect to NCSU network (on-campus or through VPN)\n",
    "if \"nc250\" not in os.listdir(\"data/DEM\"):\n",
    "    # URL to the North Carolina boundary 250m DEM\n",
    "    url = \"https://gisdata.lib.ncsu.edu/DEM/nc250.zip\"\n",
    "    zip_file_name = \"nc250.zip\"\n",
    "    # Download the zip file from the URL\n",
    "    urllib.request.urlretrieve(url, zip_file_name)\n",
    "    # Extract the contents of the zip file to a directory named \"data/DEM\"\n",
    "    with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data/DEM\")\n",
    "        \n",
    "if \"nc250\" not in arcpy.ListRasters():\n",
    "    arcpy.management.CopyRaster(\"data/DEM/nc250\", \"nc250\", nodata_value=\"-3.402823e+38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 6, 2023 8:41:20 PM\",\"WARNING 110419: Raster cell values could not be extracted for 29 of 8248 training locations.\",\"\\n------------------------------- Count of Presence and Background Points -------------------------------\\n                              From Input Point Features   Used in Training Model   Classified as Presence\\nNumber of Presence Points     8248                        337                      201                   \\nNumber of Background Points   0                           15101                    2742                  \\n\",\"\\n-------------------------- Model Characteristics --------------------------\\nExplanatory Variable Expansions (Basis Functions)     Smoothed step (Hinge)\\nNumber of Knots                                       10                   \\nStudy Area                                            Raster Extent        \\nSpatial Thinning Minimum Neighbor Distance            2500 Meters          \\nRelative Weight of Presence to Background             100                  \\nPresence Probability Transformation (Link Function)   c-log-log            \\nPresence Probability Cutoff                           0.5000               \\n\",\"\\n--- Model Summary ----\\nOmission Rate   0.4036\\nAUC             0.7819\\n\",\"\\n-------------- Regression Coefficients ---------------\\nVariable                                   Coefficient\\nhinge(NC250, 2)                            0.1138     \\nhinge(NC250, 4)                            -0.7547    \\nhinge(NC250, 9)                            0.7752     \\nhinge(NC250, 10)                           -0.0196    \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 11)   -0.5956    \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 21)   1.3540     \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 22)   1.5653     \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 23)   1.7838     \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 24)   1.7171     \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 31)   1.1443     \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 41)   -0.0747    \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 42)   -0.2646    \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 52)   -0.5162    \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 71)   -0.6847    \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 81)   0.2353     \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 82)   -0.9144    \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 90)   -1.0857    \\ncategorical(NC_NLCD2019_RESAMPLE_1K, 95)   -0.4130    \\n\",\"****************************\\n* Hinge Intervals of NC250 *\\n****************************\\n*******************************************************************************\\n\\nKnot order   Variable           Lower bound   Upper Bound   Hinge Function Type\\n0            hinge(NC250, 0)    0.0000        1824.1891     Forward Hinge      \\n1            hinge(NC250, 1)    202.6877      1824.1891     Forward Hinge      \\n2            hinge(NC250, 2)    405.3753      1824.1891     Forward Hinge      \\n3            hinge(NC250, 3)    608.0630      1824.1891     Forward Hinge      \\n4            hinge(NC250, 4)    810.7507      1824.1891     Forward Hinge      \\n5            hinge(NC250, 5)    1013.4384     1824.1891     Forward Hinge      \\n6            hinge(NC250, 6)    1216.1260     1824.1891     Forward Hinge      \\n7            hinge(NC250, 7)    1418.8137     1824.1891     Forward Hinge      \\n8            hinge(NC250, 8)    1621.5014     1824.1891     Forward Hinge      \\n9            hinge(NC250, 9)    0.0000        202.6877      Reverse Hinge      \\n10           hinge(NC250, 10)   0.0000        405.3753      Reverse Hinge      \\n11           hinge(NC250, 11)   0.0000        608.0630      Reverse Hinge      \\n12           hinge(NC250, 12)   0.0000        810.7507      Reverse Hinge      \\n13           hinge(NC250, 13)   0.0000        1013.4384     Reverse Hinge      \\n14           hinge(NC250, 14)   0.0000        1216.1260     Reverse Hinge      \\n15           hinge(NC250, 15)   0.0000        1418.8137     Reverse Hinge      \\n16           hinge(NC250, 16)   0.0000        1621.5014     Reverse Hinge      \\n17           hinge(NC250, 17)   0.0000        1824.1891     Reverse Hinge      \\n\\n*******************************************************************************\",\"\\n-------------------------------------------------- Cross-Validation Summary -------------------------------------------------\\nGroup ID   Training Size   Validation Size   % Presence - Correctly Classified   % Background - Classified as Potential Presence\\n1                  12350              3088                               58.49                                             16.51\\n2                  12350              3088                               66.67                                             25.44\\n3                  12350              3088                               50.68                                             18.97\\n4                  12351              3087                               61.84                                             18.93\\n5                  12351              3087                               50.00                                             16.65\\n\",\"WARNING 110427: Prediction values for 15 of 136382 features had to be extrapolated due to explanatory variable values outside of training data ranges.\",\"\\n----------------------------- Explanatory Variable Range Diagnostics ----------------------------\\n                            Training                                                                 \\nVariable   Features (after thinning)             Rasters                                             \\n                             Minimum   Maximum   Minimum   Maximum   Count outside training range (%)\\nNC250                           0.00   1824.19      0.00   1999.64                          15 (0.01)\\n\",\"\\n------------------------ Explanatory Variable Category Diagnostics -------------------------\\n                          Training                                                             \\nVariable                  Features (after thinning)                  Rasters                   \\n                          Categories                     Count (%)   Categories       Count (%)\\nNC_NLCD2019_RESAMPLE_1K   11                           1199 (7.77)   11            10908 (8.00)\\n                          21                           1416 (9.17)   21            11691 (8.57)\\n                          22                            509 (3.30)   22             4212 (3.09)\\n                          23                            197 (1.28)   23             1742 (1.28)\\n                          24                             60 (0.39)   24              496 (0.36)\\n                          31                             36 (0.23)   31              298 (0.22)\\n                          41                          2873 (18.61)   41           25641 (18.80)\\n                          42                          2125 (13.76)   42           19038 (13.96)\\n                          43                           1350 (8.74)   43            11369 (8.34)\\n                          52                            363 (2.35)   52             3217 (2.36)\\n                          71                            300 (1.94)   71             2778 (2.04)\\n                          81                            978 (6.34)   81             8795 (6.45)\\n                          82                          1900 (12.31)   82           17174 (12.59)\\n                          90                          1949 (12.62)   90           17400 (12.76)\\n                          95                            183 (1.19)   95             1623 (1.19)\\n\",\"Succeeded at Monday, March 6, 2023 8:42:39 PM (Elapsed Time: 1 minutes 18 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Users/bento/OneDrive/code_and_data/ncsu-mgist/courses/gis_540/final_project/woodpecker-nc\\\\fw_GDB.gdb\\\\Downy_Woodpecker_NC_Trained_Features'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/presence-only-prediction.htm\n",
    "\n",
    "arcpy.stats.PresenceOnlyPrediction(input_point_features=\"FW_Downy_Woodpecker_NC\", \n",
    "                                   contains_background=\"PRESENCE_ONLY_POINTS\", \n",
    "                                   explanatory_variables=None, #TODO\n",
    "                                   presence_indicator_field=None, \n",
    "                                   distance_features=None, \n",
    "                                   explanatory_rasters=[[\"nc_nlcd2019_Resample_1k\", \"true\"], \n",
    "                                                        [\"nc250\", \"false\"]], \n",
    "                                   basis_expansion_functions=\"HINGE\", \n",
    "                                   number_knots=10, \n",
    "                                   study_area_type=\"RASTER_EXTENT\", \n",
    "                                   study_area_polygon=None, \n",
    "                                   spatial_thinning=\"THINNING\", \n",
    "                                   thinning_distance_band=\"2500 Meters\", \n",
    "                                   number_of_iterations=20, \n",
    "                                   relative_weight=100,  #1-100\n",
    "                                   link_function=\"CLOGLOG\", \n",
    "                                   presence_probability_cutoff=0.5, \n",
    "                                   output_trained_features=\"Downy_Woodpecker_NC_Trained_Features\", \n",
    "                                   output_trained_raster=\"Downy_Woodpecker_NC_Trained_Raster\", \n",
    "                                   output_response_curve_table=\"Downy_Woodpecker_NC_Response_Curve\", \n",
    "                                   output_sensitivity_table=\"Downy_Woodpecker_NC_Sensitivity_Table\", \n",
    "                                   features_to_predict=None, \n",
    "                                   output_pred_features=None, \n",
    "                                   output_pred_raster=None, \n",
    "                                   explanatory_variable_matching=None, \n",
    "                                   explanatory_distance_matching=None, \n",
    "                                   explanatory_rasters_matching=None, \n",
    "                                   allow_predictions_outside_of_data_ranges=\"ALLOWED\", \n",
    "                                   resampling_scheme=\"RANDOM\", \n",
    "                                   number_of_groups=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fc in [\"Downy_Woodpecker_NC_Trained_Features\", \n",
    "           \"Downy_Woodpecker_NC_Trained_Raster\", \n",
    "           \"Downy_Woodpecker_NC_Response_Curve\", \n",
    "           \"Downy_Woodpecker_NC_Sensitivity_Table\"]:\n",
    "    if fc in arcpy.ListTables() or fc in arcpy.ListFeatureClasses():\n",
    "        print(fc)\n",
    "        arcpy.Delete_management(fc)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ppt', 2017),\n",
       " ('ppt', 2018),\n",
       " ('ppt', 2019),\n",
       " ('tmax', 2017),\n",
       " ('tmax', 2018),\n",
       " ('tmax', 2019),\n",
       " ('tmin', 2017),\n",
       " ('tmin', 2018),\n",
       " ('tmin', 2019)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vars = [\"ppt\", \"tmax\", \"tmin\"]\n",
    "yrs = [2017, 2018, 2019]\n",
    "\n",
    "pairs = list()\n",
    "pairs = [(v, y) for v in vars for y in yrs if (v, y) not in pairs]\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f192acd1de90387fc8829f885aaa95d2215ac7117848e2dc5e90bd1eb94ec849"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
